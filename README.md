# Behavioral Cloning Project

## Introduction

The purpose of this project was to train a car to drive by itself in a computer simulation. For the purposes of training we used the pretrained Inception V3 architecture. It proved to be more than adequate for thsi problem.

## Data generation, preparation and augmentation

About half of our training data was the dataset provided by Udacity, while the rest was 
based on about four laps recorded on track 1 and one lap recorded on track 2. Both the validation and the testing datasets were entirely generated by recording laps around the track 1.

In total, we've had over 30,000 data points. However, most of the datapoints were thsoe for which the steering wheel was turned by 0 degrees. In order to eliminate the bias for 0 degree angle, I decided to use between 4% and 10% of the 0 degree data, depending on the dataset.

I have tried several approaches to data augmentation. Since the first track (for which we have the most data) goes predominatly in the counterclockwise direction, there was a bias in the data for the negative stering angles. In order to rectify that, I decided to flip all the images as additional data points with the corresponding 0 degree angles. This lead to the final training set of about 13,000 data points/images.

I have also tried darkening/lightening subsets of training images, but that did not have a major effect on the quality of training. 

In order to enhance the relevance of the part of the image for training, we cropped it to include just the middle 160x160 square. This significantly improved our error rate (from about 0.09 mse down to 0.06 mse). Finally, in order to make the optimum use of teh Inception architecture, we scaled the images to 299x299. Other input image sizes that I've tried were 160x320, 160x160 and 140x160. However the 299x299 proved to give the best results. 

Here is an example of the original training image and a correponding cropped one:

[image1]

[image2]

[image1]: road1.png
[image2]: road2.png



## Neural Network and Training

For this assignment I wanted to see if it could be possible to use one of the Keras pretrained networks. I decided to use the Google's Inception V3 network that has been trained on ImageNet dataset. I have changed the output layer to use 2D Average Pooling and just one regression output dimension. The entire network consists of 174 layers, and its architecture can be seen in teh NN.txt file.

I have tried two different optimizers for this network configuration: SGD and Adam. For SGD I have tried learnign rates in teh range 0.000001 to 0.0001, but the best results I was getting were about 0.1x mse. I have tried optimizing the number of epochs using early stopping, but that didn't work too well. I also tried "freezing" the first 172 layers, and just fine-tuning the last layer, but that did not work well at all. Aside from all the In te end, I ended up with Adam optimizer and 10 epochs. The final validation mse was about 0.063, with test mse of about 0.065. 

All training fro this problem has been done on a Ubuntu 16.04 machine with 64 GB of RAM and Nvidia GTX 1070 GPU.

## Testing

I used the simulator in the autonomus mode, and the car drove around the track 1 quite well. I had to fiddle with the constant thrust in order to get the smoothest ride. The car works well with the default value of 0.2, but the ride is much smoother at the lower values of thrust. The optimal performance in terms of speed/quality was achieved at about 0.15. At thrusts that are above 0.3 the car eventually lost control and swerved outside of the track. 

I also tested the model on track 2. Here car perfomed much better at the higher thrust of about 0.3. However, car was unable to clear one really sharp turn at the latter portion of the track. My suspicion is that this was primarily due to the darth of very sharp steering angles at the altter in the training datset, and perhaps a more balanced dataset woudl have made a difference here. 

## Conclusion

Overall, I am very satisfied with the results of this exercise. The car performed very well on track 1, and almost made it all teh way through track 2. With more time to acquire additional data fro very sharp angles, and/or augment the existing dataset, it is very likely that I owuld have been able to train the neural network to drive on this track as well. 

I was also very pleased that I was able to train an existing pre-trained Inception network. This shows the varsetility and daptabuility of the standard deep learning architectures. However, it is possible that a smaller and more ad-hoc network would have done teh job just as well. 
